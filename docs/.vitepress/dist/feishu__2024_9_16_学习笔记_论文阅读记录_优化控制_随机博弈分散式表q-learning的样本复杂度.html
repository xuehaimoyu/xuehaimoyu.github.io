<!DOCTYPE html>
<html lang="中文" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>随机博弈分散式表q-learning的样本复杂度 | 个人博客</title>
    <meta name="description" content="一个记录生活与学习笔记的平台">
    <meta name="generator" content="VitePress v1.4.1">
    <link rel="preload stylesheet" href="/assets/style.z3BgEwrS.css" as="style">
    
    <script type="module" src="/assets/app.DjPFyMcR.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.BIw2Au4A.js">
    <link rel="modulepreload" href="/assets/chunks/framework.DrEU2cf2.js">
    <link rel="modulepreload" href="/assets/chunks/Rm93ba9rAotYekxwKbmcyVvUnRe.D9-dw4TE.js">
    <link rel="modulepreload" href="/assets/feishu__2024_9_16_学习笔记_论文阅读记录_优化控制_随机博弈分散式表q-learning的样本复杂度.md.BwL8PZpo.lean.js">
    <link rel="icon" href="favicon.ico">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-59fbf6df><!--[--><!--]--><!--[--><span tabindex="-1" data-v-cf22919c></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-cf22919c> Skip to content </a><!--]--><!----><header class="VPNav" data-v-59fbf6df data-v-fc0d7fd6><div class="VPNavBar" data-v-fc0d7fd6 data-v-c8340891><div class="wrapper" data-v-c8340891><div class="container" data-v-c8340891><div class="title" data-v-c8340891><div class="VPNavBarTitle has-sidebar" data-v-c8340891 data-v-a94ffaa7><a class="title" href="/" data-v-a94ffaa7><!--[--><!--]--><!----><span data-v-a94ffaa7>个人博客</span><!--[--><!--]--></a></div></div><div class="content" data-v-c8340891><div class="content-body" data-v-c8340891><!--[--><!--]--><div class="VPNavBarSearch search" data-v-c8340891><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-c8340891 data-v-3d3a5d5d><span id="main-nav-aria-label" class="visually-hidden" data-v-3d3a5d5d> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-3d3a5d5d data-v-5f8976a1><!--[--><span data-v-5f8976a1>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/feishu__2024_8_26__%E6%97%A5%E5%B8%B8%E5%8D%9A%E5%AE%A2.html" tabindex="0" data-v-3d3a5d5d data-v-5f8976a1><!--[--><span data-v-5f8976a1>日常博客</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/feishu__2024_8_27__%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" tabindex="0" data-v-3d3a5d5d data-v-5f8976a1><!--[--><span data-v-5f8976a1>学习笔记</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/feishu__2024_9_31__%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2.html" tabindex="0" data-v-3d3a5d5d data-v-5f8976a1><!--[--><span data-v-5f8976a1>技术博客</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/feishu__2024_9_31__%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95.html" tabindex="0" data-v-3d3a5d5d data-v-5f8976a1><!--[--><span data-v-5f8976a1>旅途记录</span><!--]--></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-c8340891 data-v-76c3833d data-v-fb14ba6e><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-fb14ba6e><span class="text" data-v-fb14ba6e><span class="vpi-languages option-icon" data-v-fb14ba6e></span><!----><span class="vpi-chevron-down text-icon" data-v-fb14ba6e></span></span></button><div class="menu" data-v-fb14ba6e><div class="VPMenu" data-v-fb14ba6e data-v-6985cfd1><!----><!--[--><!--[--><div class="items" data-v-76c3833d><p class="title" data-v-76c3833d>中文</p><!--[--><div class="VPMenuLink" data-v-76c3833d data-v-df46f52f><a class="VPLink link" href="/en/feishu__2024_9_16_学习笔记_论文阅读记录_优化控制_随机博弈分散式表q-learning的样本复杂度.html" data-v-df46f52f><!--[--><span data-v-df46f52f>English</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-c8340891 data-v-04c8a57c><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-04c8a57c data-v-40fffae9 data-v-657183c8><span class="check" data-v-657183c8><span class="icon" data-v-657183c8><!--[--><span class="vpi-sun sun" data-v-40fffae9></span><span class="vpi-moon moon" data-v-40fffae9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-c8340891 data-v-d1fca040 data-v-974c6b22><!--[--><a class="VPSocialLink no-icon" href="https://github.com/xuehaimoyu" aria-label="github" target="_blank" rel="noopener" data-v-974c6b22 data-v-a7e68098><span class="vpi-social-github" /></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-c8340891 data-v-5dcac945 data-v-fb14ba6e><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-fb14ba6e><span class="vpi-more-horizontal icon" data-v-fb14ba6e></span></button><div class="menu" data-v-fb14ba6e><div class="VPMenu" data-v-fb14ba6e data-v-6985cfd1><!----><!--[--><!--[--><div class="group translations" data-v-5dcac945><p class="trans-title" data-v-5dcac945>中文</p><!--[--><div class="VPMenuLink" data-v-5dcac945 data-v-df46f52f><a class="VPLink link" href="/en/feishu__2024_9_16_学习笔记_论文阅读记录_优化控制_随机博弈分散式表q-learning的样本复杂度.html" data-v-df46f52f><!--[--><span data-v-df46f52f>English</span><!--]--></a></div><!--]--></div><div class="group" data-v-5dcac945><div class="item appearance" data-v-5dcac945><p class="label" data-v-5dcac945>Appearance</p><div class="appearance-action" data-v-5dcac945><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-5dcac945 data-v-40fffae9 data-v-657183c8><span class="check" data-v-657183c8><span class="icon" data-v-657183c8><!--[--><span class="vpi-sun sun" data-v-40fffae9></span><span class="vpi-moon moon" data-v-40fffae9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-5dcac945><div class="item social-links" data-v-5dcac945><div class="VPSocialLinks social-links-list" data-v-5dcac945 data-v-974c6b22><!--[--><a class="VPSocialLink no-icon" href="https://github.com/xuehaimoyu" aria-label="github" target="_blank" rel="noopener" data-v-974c6b22 data-v-a7e68098><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-c8340891 data-v-2bbfb3cb><span class="container" data-v-2bbfb3cb><span class="top" data-v-2bbfb3cb></span><span class="middle" data-v-2bbfb3cb></span><span class="bottom" data-v-2bbfb3cb></span></span></button></div></div></div></div><div class="divider" data-v-c8340891><div class="divider-line" data-v-c8340891></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-59fbf6df data-v-a1d832f8><div class="container" data-v-a1d832f8><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a1d832f8><span class="vpi-align-left menu-icon" data-v-a1d832f8></span><span class="menu-text" data-v-a1d832f8>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a1d832f8 data-v-8ea835dd><button data-v-8ea835dd>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-59fbf6df data-v-18d98619><div class="curtain" data-v-18d98619></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18d98619><span class="visually-hidden" id="sidebar-aria-label" data-v-18d98619> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-08d057c1><section class="VPSidebarItem level-0 collapsible is-link" data-v-08d057c1 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_8_26__%E6%97%A5%E5%B8%B8%E5%8D%9A%E5%AE%A2.html" data-v-fd4de8f7><!--[--><h2 class="text" data-v-fd4de8f7>日常博客</h2><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-1 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_8_26_%E6%97%A5%E5%B8%B8%E5%8D%9A%E5%AE%A2_%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%BA%AA%E5%BF%B5.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>个人博客搭建纪念</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-08d057c1><section class="VPSidebarItem level-0 collapsible is-link" data-v-08d057c1 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_31__%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2.html" data-v-fd4de8f7><!--[--><h2 class="text" data-v-fd4de8f7>技术博客</h2><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-1 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_31_%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2_vitepress%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA%E4%B8%8E%E6%9B%B4%E6%96%B0%E8%AE%B0%E5%BD%95.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>Vitepress网站搭建与更新记录</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2_%E5%81%8F%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%B1%82%E8%A7%A3%E6%80%BB%E7%BB%93.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>偏微分方程求解总结</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_15_%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2_vscode%E7%BC%96%E8%AF%91latex%E6%95%99%E7%A8%8B.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>VScode编译latex教程</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-08d057c1><section class="VPSidebarItem level-0 collapsible is-link" data-v-08d057c1 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_31__%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95.html" data-v-fd4de8f7><!--[--><h2 class="text" data-v-fd4de8f7>旅途记录</h2><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><section class="VPSidebarItem level-1 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_31_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD.html" data-v-fd4de8f7><!--[--><h3 class="text" data-v-fd4de8f7>中国</h3><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><section class="VPSidebarItem level-2 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E4%B8%8A%E6%B5%B7.html" data-v-fd4de8f7><!--[--><h4 class="text" data-v-fd4de8f7>上海</h4><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E4%B8%8A%E6%B5%B7_%E5%A4%96%E6%BB%A9%20%E9%99%86%E5%AE%B6%E5%98%B4.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>外滩 陆家嘴</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E4%B8%8A%E6%B5%B7_%E4%B8%B4%E6%B8%AF%20%E6%BB%B4%E6%B0%B4%E6%B9%96%20%E4%B8%9C%E6%B5%B7.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>临港 滴水湖 东海</p><!--]--></a><!----></div><!----></div><!--]--></div></section><div class="VPSidebarItem level-2 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E4%BA%91%E5%8D%97.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>云南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E5%8C%97%E4%BA%AC.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>北京</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-2 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E5%B9%BF%E4%B8%9C.html" data-v-fd4de8f7><!--[--><h4 class="text" data-v-fd4de8f7>广东</h4><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_8_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E5%B9%BF%E4%B8%9C_%E6%B7%B1%E5%9C%B3.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>深圳</p><!--]--></a><!----></div><!----></div><!--]--></div></section><div class="VPSidebarItem level-2 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E5%9B%9B%E5%B7%9D.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>四川</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-2 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_14_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E6%B5%99%E6%B1%9F.html" data-v-fd4de8f7><!--[--><h4 class="text" data-v-fd4de8f7>浙江</h4><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_14_%E6%97%85%E9%80%94%E8%AE%B0%E5%BD%95_%E4%B8%AD%E5%9B%BD_%E6%B5%99%E6%B1%9F_%E7%BB%8D%E5%85%B4.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>绍兴</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-08d057c1><section class="VPSidebarItem level-0 collapsible is-link has-active" data-v-08d057c1 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_8_27__%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" data-v-fd4de8f7><!--[--><h2 class="text" data-v-fd4de8f7>学习笔记</h2><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><section class="VPSidebarItem level-1 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_8_27_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E5%AF%BC%E8%AF%BB.html" data-v-fd4de8f7><!--[--><h3 class="text" data-v-fd4de8f7>论文导读</h3><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-2 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_31_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E5%AF%BC%E8%AF%BB_prl%20%20volume%20133%20%E9%83%A8%E5%88%86%E6%96%87%E7%AB%A0%E5%AF%BC%E8%AF%BB.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>PRL Volume 133 部分文章导读</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible is-link has-active" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_8_27_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95.html" data-v-fd4de8f7><!--[--><h3 class="text" data-v-fd4de8f7>论文阅读记录</h3><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><section class="VPSidebarItem level-2 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_8_27_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97.html" data-v-fd4de8f7><!--[--><h4 class="text" data-v-fd4de8f7>量子计算</h4><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_8_27_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97_optimal%20simulation%20of%20deutsch%20gates%20and%20the%20fredkin%20gate.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>Optimal simulation of Deutsch gates and the Fredkin gate</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_8_28_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97_fast%20multiqubit%20gates%20through%20simultaneous%20two-qubit%20gates.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>Fast Multiqubit Gates through Simultaneous Two-Qubit Gates</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_6_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97_%E5%8F%98%E5%88%86%E9%87%8F%E5%AD%90kan.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>变分量子KAN</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_8_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A3%80%E6%B5%8B%E9%87%8F%E5%AD%90%E7%BA%A0%E7%BC%A0.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>无监督学习检测量子纠缠</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_5_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97_%E5%90%84%E5%90%91%E5%BC%82%E6%80%A7%E4%B8%8D%E5%8F%98%E6%80%A7%E5%92%8C%E9%87%8F%E5%AD%90%E7%9B%B8%E5%85%B3%E7%9A%84%E5%88%86%E5%B8%83%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>各向异性不变性和量子相关的分布</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-2 collapsible is-link has-active" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_16_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E4%BC%98%E5%8C%96%E6%8E%A7%E5%88%B6.html" data-v-fd4de8f7><!--[--><h4 class="text" data-v-fd4de8f7>优化控制</h4><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_16_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E4%BC%98%E5%8C%96%E6%8E%A7%E5%88%B6_%E9%9A%8F%E6%9C%BA%E5%8D%9A%E5%BC%88%E5%88%86%E6%95%A3%E5%BC%8F%E8%A1%A8q-learning%E7%9A%84%E6%A0%B7%E6%9C%AC%E5%A4%8D%E6%9D%82%E5%BA%A6.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>随机博弈分散式表q-learning的样本复杂度</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section><section class="VPSidebarItem level-1 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_1_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86.html" data-v-fd4de8f7><!--[--><h3 class="text" data-v-fd4de8f7>学习笔记整理</h3><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-2 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_5_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86_%E5%90%8D%E8%AF%8D%E8%AF%8D%E5%85%B8.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>名词词典及解释</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-2 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_7_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86_%E9%87%8F%E5%AD%90%E7%90%86%E8%AE%BA.html" data-v-fd4de8f7><!--[--><h4 class="text" data-v-fd4de8f7>量子理论</h4><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_10_7_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86_%E9%87%8F%E5%AD%90%E7%90%86%E8%AE%BA_%E9%AB%98%E7%AD%89%E9%87%8F%E5%AD%90%E5%8A%9B%E5%AD%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>高等量子力学学习笔记</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-2 collapsible is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" tabindex="0" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_16_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86_ai%E5%AD%A6%E4%B9%A0.html" data-v-fd4de8f7><!--[--><h4 class="text" data-v-fd4de8f7>AI学习</h4><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-fd4de8f7><span class="vpi-chevron-right caret-icon" data-v-fd4de8f7></span></div></div><div class="items" data-v-fd4de8f7><!--[--><div class="VPSidebarItem level-3 is-link" data-v-fd4de8f7 data-v-fd4de8f7><div class="item" data-v-fd4de8f7><div class="indicator" data-v-fd4de8f7></div><a class="VPLink link link" href="/feishu__2024_9_16_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86_ai%E5%AD%A6%E4%B9%A0_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.html" data-v-fd4de8f7><!--[--><p class="text" data-v-fd4de8f7>强化学习</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-59fbf6df data-v-619b90b6><div class="VPDoc has-sidebar has-aside" data-v-619b90b6 data-v-5403d36d><!--[--><!--]--><div class="container" data-v-5403d36d><div class="aside" data-v-5403d36d><div class="aside-curtain" data-v-5403d36d></div><div class="aside-container" data-v-5403d36d><div class="aside-content" data-v-5403d36d><div class="VPDocAside" data-v-5403d36d data-v-dbe6b52b><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-dbe6b52b data-v-a26deb35><div class="content" data-v-a26deb35><div class="outline-marker" data-v-a26deb35></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a26deb35>On this page</div><ul class="VPDocOutlineItem root" data-v-a26deb35 data-v-0df9a4ed><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-dbe6b52b></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5403d36d><div class="content-container" data-v-5403d36d><!--[--><!--]--><main class="main" data-v-5403d36d><div style="position:relative;" class="vp-doc _feishu__2024_9_16_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E4%BC%98%E5%8C%96%E6%8E%A7%E5%88%B6_%E9%9A%8F%E6%9C%BA%E5%8D%9A%E5%BC%88%E5%88%86%E6%95%A3%E5%BC%8F%E8%A1%A8q-learning%E7%9A%84%E6%A0%B7%E6%9C%AC%E5%A4%8D%E6%9D%82%E5%BA%A6" data-v-5403d36d><div><p>文章链接：<a href="https://ieeexplore.ieee.org/document/10155822" target="_blank" rel="noreferrer">https://ieeexplore.ieee.org/document/10155822</a></p><h2 id="摘要" tabindex="-1">摘要 <a class="header-anchor" href="#摘要" aria-label="Permalink to &quot;摘要&quot;">​</a></h2><p>本文针对一般和随机对策的一个重要子类——弱无循环随机对策，在表格设置下对分散q -学习算法进行了有限样本分析，其中包括潜在对策和马尔科夫团队问题作为特例。在实际而具有挑战性的分散设置中，每个代理都无法观察到其他代理的奖励和行为。事实上，每个主体都可以完全忽略其他决策者的存在。本文研究了[1]中的分散式表q学习算法收敛到马尔可夫完美均衡的样本复杂度。</p><p>文章关注多智能体随机博弈的学习问题，特别是在无中心控制的分散式环境中实现有效学习的挑战。在这种场景下，每个智能体只能获取局部信息（自身的状态和奖励），而无法获知其他智能体的行动和奖励。该研究重点在弱循环随机博弈上，这类博弈包含了潜在博弈和马尔可夫团队问题。在这类博弈中，如果各智能体遵循最优回复（Best Reply）策略，则系统可以在某些条件下避免陷入不可逆的振荡。因此，弱循环博弈被认为具有实现稳定均衡的潜力</p><h2 id="引言与背景" tabindex="-1">引言与背景 <a class="header-anchor" href="#引言与背景" aria-label="Permalink to &quot;引言与背景&quot;">​</a></h2><p>多智能体学习近年来成为研究的热点领域，特别是在需要多个智能体在同一环境中协作完成任务的应用中，例如网络路由、能源分配、交通控制、机器人系统和社会经济问题等。在这些系统中，各个智能体（也称为“代理”）通过与环境交互来学习如何完成任务，且智能体之间并没有完全的合作关系。引言强调了这种多智能体环境中智能体之间的交互复杂性：每个智能体的行为会影响整个环境，从而影响其他智能体的决策过程。</p><p>更具体的研究问题：</p><p>随机博弈（Stochastic Games），又称为马尔可夫博弈，是建模动态多智能体交互的经典框架。随机博弈与重复博弈不同，它不仅关注各阶段的独立决策，还考虑了各阶段之间的状态变化——当前阶段的状态由上一阶段各智能体的联合动作决定。这种动态特性使得随机博弈适用于更广泛的问题设置，例如智能体可能处于网络中，也可能不相连。</p><p>随机博弈包括了多种情景：比如，两智能体的零和博弈（一个智能体的奖励为负数表示竞争关系）以及多智能体的一般和博弈（每个智能体都有独立的奖励函数，且可能存在多个智能体）。此外，随机博弈可以是有限时间的，也可以是无限时间的，智能体的目标是选择策略以最大化其总奖励（若时间有限）或折现奖励（若时间无限）。</p><p>在多智能体博弈中，最常研究的一个均衡概念是“马尔可夫完美均衡”（Markov Perfect Equilibrium, MPE）。该均衡意味着每个智能体的策略不仅仅是当前状态的最佳响应，还必须是所有其他智能体联合策略的最佳响应，即所有智能体都通过彼此的策略组合实现了最优回报。马尔可夫完美均衡是一种子博弈精炼均衡（subgame perfect equilibrium），意味着智能体的策略在每一个状态下都是局部最优的，从而能获得全局的长期利益。</p><p>随着强化学习的兴起，将强化学习的方法应用于随机博弈越来越受到关注。在多智能体系统中，多个智能体通过试错方式与随机环境交互，从而在不确定的环境中学习策略。强化学习中的Q学习是一个典型的例子，但在多智能体系统中，它面临着特有的挑战——在分散式环境中，各智能体无法观察其他智能体的奖励和动作，因此，Q学习的收敛性很难保证。</p><p>强化学习算法可以分为 <strong>集中式</strong>和 <strong>分散式</strong>两类：</p><ul><li>在集中式算法中，存在一个中央控制器，它可以访问所有智能体的奖励和策略信息，并进行协调。</li><li>在分散式算法中，每个智能体基于局部信息独立决策，这种环境下的学习算法收敛性难以保证，原因在于多智能体系统的状态和奖励取决于所有智能体的联合行动，因此每个智能体面临的环境具有非平稳性。</li></ul><p>引言指出，在多智能体系统中，由于所有智能体的策略都在变化，环境是非平稳的，因此直接扩展单智能体的学习算法（如Q学习）可能导致非收敛性。解决非平稳性问题是开发分散式学习算法时的关键挑战。</p><p>为了应对这一问题，已有研究提出了一种分散式Q学习算法。在这种算法中，每个智能体在不同时段保持策略不变的时间足够长（称为“探索阶段”），从而让环境对每个智能体而言在短时间内近似为静态。在探索阶段期间，智能体更新Q值，而策略更新则在探索阶段结束时根据Q值进行。这种“先探索再更新”的方法重复进行，以使得智能体的联合策略逐渐收敛到马尔可夫完美均衡。</p><p>在上述研究的基础上，本文进一步研究了分散式Q学习算法的 <strong>样本复杂度</strong>，即在有限样本的情况下，算法收敛到马尔可夫完美均衡所需的样本数量。本文提出了以下新成果：</p><ul><li><strong>首次推导出多智能体一般和随机博弈的样本复杂度</strong>，并展示了该样本复杂度与博弈参数之间的关系。</li><li>提出了样本复杂度的 <strong>上下界估计</strong>，并解决了一些隐含参数的非显性问题（如最小稳态分布概率和混合时间）。</li><li>为确保收敛到均衡，本文扩展了弱循环博弈的相关理论，提出了一些必要的假设，并在算法上进行了改进，以支持非渐进收敛。</li></ul><p>分散式Q-learning具体参考文章：</p><p><a href="https://arxiv.org/abs/1506.07924" target="_blank" rel="noreferrer">https://arxiv.org/abs/1506.07924</a></p><p>本文特别关注一般和随机博弈中的一个重要子类： <strong>弱循环随机博弈（weakly acyclic stochastic games）</strong>。这一子类包含了以下两种特殊类型的博弈：</p><ol><li><strong>潜在博弈（Potential Games）</strong> 潜在博弈是一种特殊的博弈形式，其中所有智能体的策略调整都可以被看作是优化同一个潜在函数。因此，任何一个智能体的策略改变都会导致这个潜在函数的值变化，从而使得系统逐步朝向均衡状态演化。这种博弈的结构特性使得各智能体可以通过逐步调整策略，达到一个局部或全局的稳定均衡。</li><li><strong>马尔可夫团队问题（Markov Team Problems）</strong> 在马尔可夫团队问题中，所有智能体共享一个共同的目标，即最大化整个团队的总回报。每个智能体的策略调整都是为了优化这个共同的目标函数，这与潜在博弈类似，但更加专注于协作。智能体之间的互动不是相互竞争的，而是为了实现团队的整体最优。</li></ol><h3 id="为什么选择弱循环随机博弈作为研究子类" tabindex="-1">为什么选择弱循环随机博弈作为研究子类？ <a class="header-anchor" href="#为什么选择弱循环随机博弈作为研究子类" aria-label="Permalink to &quot;为什么选择弱循环随机博弈作为研究子类？&quot;">​</a></h3><p>弱循环随机博弈的一个重要特性是：在该类博弈中，每个智能体都可以通过“最优回复路径”（Best Reply Path）逐步调整策略，从而避免陷入不可逆的循环状态，最终收敛到一个稳定的均衡。这种结构特点使得它特别适合应用于分散式学习算法的研究，因为智能体能够在不直接观测其他智能体行为的情况下，逐步调整到一个均衡策略组合。这类博弈结构在不确定的多智能体环境中确保了算法的收敛性。</p><h2 id="相关概念" tabindex="-1">相关概念 <a class="header-anchor" href="#相关概念" aria-label="Permalink to &quot;相关概念&quot;">​</a></h2><p>文章的第二节主要介绍了 <strong>弱循环随机博弈</strong>和最优回复过程（Best Reply Process with Inertia）的相关预备知识，并为后续算法分析提供了理论基础。本节详细定义了弱循环随机博弈的形式化描述，给出了智能体的收益函数和最优策略的数学定义，并阐明了在弱循环博弈中，如何通过特定的最优回复路径逐步收敛到均衡。以下是对第二节内容的详细解析及公式说明：</p><p>在文章中，随机博弈被描述为一个包含有限状态和动作集的多智能体动态系统，形式化定义如下：</p><ul><li><strong>智能体集合</strong>：假设有 N 个智能体，每个智能体标记为 <!---->。</li><li><strong>状态集合 S</strong>：这是博弈的状态空间，表示系统的所有可能状态。</li><li><strong>动作集合</strong><!---->：每个智能体 i都有自己的动作集合<!---->，表示该智能体可以采取的所有可能动作。系统的联合动作集为 <!---->。</li><li><strong>奖励函数</strong><!---->：表示在状态 s∈S 时，当所有智能体选择联合动作 <!---->时，第 i个智能体获得的即时奖励。奖励函数可以取不同的形式，但通常是非负值。</li><li><strong>折现因子</strong><!---->：每个智能体都有自己的折现因子，用于计算未来奖励的折现值。</li><li><strong>状态转移概率 P(s&#39;|s, a)</strong>：给定当前状态 s 和联合动作 a，系统转移到下一个状态 s&#39;的概率。这是一个马尔可夫决策过程的核心特性，表示当前状态和联合动作决定了未来状态的概率分布。</li></ul><p>智能体的策略和价值函数</p><p>对于每个智能体 i，其目标是找到一个最优策略，以最大化其在随机博弈中的累积期望折现奖励。本文将策略（Policy）定义为智能体在给定状态下选择动作的规则。</p><ul><li><strong>策略</strong><!---->：一个智能体的策略是一个从状态空间 S 映射到动作空间 <!---->的函数，表示智能体在不同状态下选择动作的规则。本文重点关注静态策略，即在每个状态下始终选择相同的策略。</li><li><strong>价值函数</strong><!---->：对于策略<!---->，智能体 i 在状态s时的价值函数定义为：</li><li><!----></li><li>其中，期望是基于联合策略 <!---->和系统的转移概率计算的。价值函数表示从状态 s 出发，按照策略 <!----> 执行动作序列的累积折现奖励。</li><li><strong>Q函数（Q-value function）</strong>：Q函数定义为在状态 s 选择某个动作 a 的长期期望回报，Q函数的定义如下：</li><li><!----></li><li>其中，<!---->表示除了智能体 i 以外的其他智能体的联合动作。Q函数用于帮助智能体选择在每个状态下的最优动作。</li></ul><h3 id="马尔可夫完美均衡的定义" tabindex="-1">马尔可夫完美均衡的定义 <a class="header-anchor" href="#马尔可夫完美均衡的定义" aria-label="Permalink to &quot;马尔可夫完美均衡的定义&quot;">​</a></h3><p>文章定义了一个在弱循环随机博弈中的重要均衡概念，即 <strong>马尔可夫完美均衡（Markov Perfect Equilibrium, MPE）</strong>。在MPE下，每个智能体的策略是其他所有智能体的策略的最优回复。MPE的数学定义为：</p><p>若策略组合<!---->满足以下条件，则称其为MPE：</p><!----><p>其中，<!----> 表示除智能体 i外的其他智能体的均衡策略组合。该条件表明，在均衡策略组合下，每个智能体的策略都是最优的，没有偏离的动机。</p><h4 id="最佳回复策略" tabindex="-1">最佳回复策略 <a class="header-anchor" href="#最佳回复策略" aria-label="Permalink to &quot;最佳回复策略&quot;">​</a></h4><p>被定义为在其他智能体策略保持不变的情况下，使智能体自身收益最大化的策略。</p><p>对于每个智能体 <!----> 和其策略组合 <!---->（即除智能体 <!----> 之外的所有智能体的策略组合），如果存在策略 <!----> 使得以下条件成立：</p><!----><p>那么称 <!----> 是在策略组合 <!----> 下，智能体 <!----> 的最佳回复策略。</p><p>其中：</p><ul><li><!----> 表示智能体 i 在状态 <!----> 下，给定自身策略 <!----> 和其他智能体策略<!----> 的情况下的价值函数（即智能体i 所能获得的期望累积折现奖励）。</li><li><!----> 表示智能体 i 的所有可能策略的集合。</li></ul><p>换句话说，最佳回复策略 <!----> 是在其他智能体策略保持不变的前提下，使得智能体 i 的期望收益最大化的策略。</p><h4 id="严格最佳回复" tabindex="-1">严格最佳回复 <a class="header-anchor" href="#严格最佳回复" aria-label="Permalink to &quot;严格最佳回复&quot;">​</a></h4><p>如果在某个状态 <!----> 下，策略 <!----> 严格优于其他策略 <!---->，即：</p><!----><p>那么称 <!----> 为智能体 i 的<strong>严格最佳回复策略</strong>。严格最佳回复意味着智能体在某些状态下对偏离该策略有更强的激励。</p><h3 id="弱循环博弈与最优回复路径" tabindex="-1">弱循环博弈与最优回复路径 <a class="header-anchor" href="#弱循环博弈与最优回复路径" aria-label="Permalink to &quot;弱循环博弈与最优回复路径&quot;">​</a></h3><p><strong>弱循环博弈</strong>是一种特殊的博弈结构，其中存在从任意策略组合到均衡策略组合的路径。也就是说，即便系统中可能存在策略调整的回路，只要智能体按照最优回复路径调整策略，系统最终可以收敛到某个均衡点。本文用严格最优回复路径来描述这样的策略调整序列：</p><ul><li><strong>严格最优回复路径</strong>：一系列策略组合<!---->其中每个策略组合都通过智能体的一个最优策略调整得到。换句话说，从一个非均衡策略出发，通过一次次最优回复策略的调整，系统最终到达均衡策略组合。</li></ul><p>假设我们有一系列的策略组合 <!---->，称其为一个严格最佳回复路径，如果对于每个<!----> 都满足以下条件：</p><p><!----> 仅与 <!----> 在一个智能体的策略上不同（即，只有一个智能体更新了策略）。</p><p>更新后的策略是一个严格最佳回复，即，假设智能体 <!----> 在 <!---->中选择了新的策略 <!---->，且</p><!----><p>则说明智能体<!---->的新策略相对于其他智能体当前策略组合 <!----> 是一个严格最佳回复。</p><p>在弱循环博弈中，每一个非均衡策略组合都存在至少一条这样的最优回复路径，这确保了系统可以在适当的调整后达到均衡。</p><p>一个随机博弈被称为<strong>弱循环随机博弈</strong>，如果它满足以下条件：</p><ul><li>存在从任意策略组合出发，到达一个均衡策略组合的严格最佳回复路径。</li></ul><p>换句话说，在弱循环随机博弈中，从任何初始策略组合出发，通过一系列的严格最佳回复路径，智能体总是能够最终收敛到某个均衡点。</p><h3 id="最优回复过程与惯性机制" tabindex="-1">最优回复过程与惯性机制 <a class="header-anchor" href="#最优回复过程与惯性机制" aria-label="Permalink to &quot;最优回复过程与惯性机制&quot;">​</a></h3><p>如果博弈的严格最佳应答图中没有循环，我们可以考虑每一步只让一个智能体切换到一个最佳应答的过程，这样的过程将持续到没有智能体有严格最佳应答，此时所有智能体的联合策略为确定性均衡联合策略。然而，如上所述，弱无环对策的严格最佳应答图可能包含环。接下来，我们引入具有惯性的最佳回复过程作为算法0，该算法为每个智能体分配一个选择其每个严格最佳回复的严格正概率。</p><p>为了解决在多智能体博弈中智能体间策略频繁变化的问题，文章提出了一个 <strong>带有惯性（Inertia）的最优回复过程（Best Reply Process with Inertia, BRPI）</strong>。在BRPI中，每个智能体在调整策略时并不总是立即采取新的最优策略，而是有一定概率保留当前策略。这一过程通过以下伪代码描述：</p><p><strong>BRPI 算法：</strong></p><ul><li><strong>输入参数</strong>：每个智能体 i的惯性参数 <!---->。</li><li><strong>初始化</strong>：为每个智能体选择一个初始策略。</li><li><strong>过程</strong>： <ol><li>在每次策略更新时，若当前策略为最优回复策略，则保持不变。</li><li>否则，智能体以概率 <!----> 保持当前策略，以 <!----> 的概率选择一个新的最优回复策略。</li></ol></li></ul><img src="/assets/X8H1bDykqoyzNoxnbzjc8qA4nJg.3pI7E58g.bmp" src-width="1018" class="markdown-img m-auto" src-height="516" align="center"><p>BRPI的核心思想在于引入惯性参数，使得智能体在策略调整时具有一定的保守性，从而减少因策略频繁变化导致的系统不稳定性。惯性机制确保系统在调整策略时逐步收敛到均衡。</p><h3 id="公式解释" tabindex="-1">公式解释 <a class="header-anchor" href="#公式解释" aria-label="Permalink to &quot;公式解释&quot;">​</a></h3><ul><li><strong>价值函数公式</strong><!----> ：表示智能体 iii 在策略 <!---->下，从状态 s出发所能获得的累积期望奖励。通过递归迭代计算，这一公式帮助智能体评估不同策略的长期收益。</li><li><strong>Q函数公式</strong> <!---->：在给定策略下，Q函数描述了每个状态-动作对的长期收益期望值，用于在每个状态下帮助智能体选择最优动作。</li><li><strong>MPE条件公式</strong> <!---->：表明在均衡状态下，每个智能体在其他智能体策略不变的前提下没有动机偏离自身策略。</li></ul><p>综上所述，第二节内容详细定义了弱循环随机博弈的基础概念，分析了最优回复路径的特性，并通过BRPI机制确保策略调整的收敛性，为后续算法和样本复杂度分析提供了坚实的理论基础。</p><h2 id="算法及复杂度分析" tabindex="-1">算法及复杂度分析 <a class="header-anchor" href="#算法及复杂度分析" aria-label="Permalink to &quot;算法及复杂度分析&quot;">​</a></h2><p>Background：</p><p>在分散式多智能体系统中，每个智能体只能观测自己的状态和获得的奖励，但无法观测其他智能体的动作和奖励。这种设置下，多智能体的策略选择会导致系统环境的非平稳性，即每个智能体在学习过程中看到的环境因其他智能体的决策而不断变化，这使得传统Q学习方法的收敛性难以保证。</p><p>为了应对这些挑战，文章引入了一个分散式Q学习算法，使得各智能体可以通过分阶段的策略更新过程逐步收敛到一个稳定的均衡状态。该算法基于分阶段的策略更新，称为探索阶段（Exploration Phase）和策略更新阶段（Policy Update Phase）。在每个探索阶段，智能体在一段时间内保持策略不变，从而使环境对每个智能体来说在此阶段近似为静态，以便每个智能体可以使用Q学习方法更新其Q值表。每个探索阶段结束时，智能体基于当前的Q表进行策略更新。</p><h3 id="具体算法" tabindex="-1">具体算法： <a class="header-anchor" href="#具体算法" aria-label="Permalink to &quot;具体算法：&quot;">​</a></h3><img src="/assets/Rm93ba9rAotYekxwKbmcyVvUnRe.BTMo21CJ.bmp" src-width="937" class="markdown-img m-auto" src-height="1202" align="center"><p>初始化阶段</p><ul><li><strong>Q表初始化</strong>：对于每个智能体 iii，初始化Q表<!---->。Q表用于存储在每个状态-动作对的估计值，即该状态-动作对的期望收益。</li><li><strong>策略初始化</strong>：为每个智能体设定初始策略 <!---->。</li><li><strong>起始状态和阶段计数</strong>：设定初始状态 <!----> 并将阶段计数器 k 设置为1。</li></ul><p>算法在循环中不断交替执行 <strong>探索阶段</strong>和 <strong>策略更新阶段</strong>，直到满足收敛条件。</p><p><strong>探索阶段</strong></p><ul><li><p><strong>时间步循环</strong>：在第 k 个探索阶段内，每个智能体保持当前的策略不变，并在多个时间步上执行动作。</p></li><li><p><strong>动作选择</strong>：智能体 i 使用<!---->贪心策略选择动作。即在当前状态 <!---->：</p><ul><li>以概率 <!---->根据当前策略选择动作，即选择Q表中当前策略对应的动作。</li><li>以概率 <!---->选择一个随机动作，从而实现探索。</li></ul></li><li><p><strong>执行动作并更新Q表</strong>：</p><ul><li>智能体执行选择的动作 <!---->，并观测到即时奖励 <!----> 和下一个状态 <!---->。</li><li>根据Q学习的更新公式更新Q值：<!----><ul><li>其中：<!---->是学习率，控制Q值更新的速度。</li><li><!---->是折现因子，表示未来奖励的权重。</li><li><!---->表示智能体从下一个状态<!----> 所能获得的最大未来回报。</li></ul></li></ul></li><li><p>这个过程在探索阶段内的每个时间步上重复执行，直到探索阶段结束。</p></li></ul><p><strong>策略更新阶段</strong></p><ul><li><p>在探索阶段结束时，进入策略更新阶段。</p></li><li><p><strong>策略更新</strong>：每个智能体i 基于当前的Q表 <!----> 更新策略 <!---->。</p><ul><li>若当前策略已经是最优策略，则以概率 <!----> 保持不变。</li><li>否则，以概率 <!---->选择新的最佳回复策略（即在当前状态选择使得Q值最大的动作作为新的策略）。</li></ul></li><li><p>这种策略更新使用了 <strong>带有惯性的最优回复过程（ BRPI）</strong>，通过惯性参数 <!----> 引入保守性，避免频繁更改策略，提高系统的稳定性。</p></li></ul><p><strong>进入下一阶段</strong></p><ul><li>在完成策略更新后，增加阶段计数 k = k + 1 并进入下一轮探索和策略更新循环。</li></ul><h3 id="非渐近收敛保证的两个关键假设" tabindex="-1">非渐近收敛保证的两个关键假设 <a class="header-anchor" href="#非渐近收敛保证的两个关键假设" aria-label="Permalink to &quot;非渐近收敛保证的两个关键假设&quot;">​</a></h3><p>在这节内容中，作者引入了两个关键假设（Assumption 1 和 Assumption 2），以保证算法在弱非循环博弈下的样本复杂度分析。</p><h4 id="假设-1-assumption-1" tabindex="-1">假设 1 (Assumption 1) <a class="header-anchor" href="#假设-1-assumption-1" aria-label="Permalink to &quot;假设 1 (Assumption 1)&quot;">​</a></h4><p>假设存在常数<!----> 和有限整数 <!---->，使得对于任意状态对 <!---->，存在一系列联合动作 <!---->，使得以下条件成立：</p><!----><p>这一假设的含义是，通过特定的联合动作序列，有一定概率从任意初始状态 <!----> 到达目标状态 <!---->，且概率的下界由常数 <!----> 给出。结合第 <!---->次探索阶段中的定义 <!---->，每个智能体在任何时刻都有一定的概率选择任意动作。这一概率与假设1结合，确保了在联合策略 <!---->引导下的马尔可夫链是不可约的。</p><h4 id="假设-2-assumption-2" tabindex="-1">假设 2 (Assumption 2) <a class="header-anchor" href="#假设-2-assumption-2" aria-label="Permalink to &quot;假设 2 (Assumption 2)&quot;">​</a></h4><p>假设对于任意联合策略 <!---->，所诱导的马尔可夫链是非周期性的。</p><p><strong>不可约性</strong>确保每个状态都能在探索阶段中被访问到，这使得算法在更新Q表时，不会因为某些状态无法访问而使得Q值学习变得不完整。</p><p><strong>非周期性</strong>意味着系统的状态不会陷入特定的循环模式，这有助于智能体更灵活地探索不同的状态，从而提升策略学习的效率。</p><p>在单智能体 Q 学习的样本复杂度分析中，通常假设马尔可夫链的行为策略是遍历的。假设1和假设2确保了马尔可夫链是有限、不可约和非周期性的，即它是均匀遍历的，且具有唯一的平稳分布。</p><p>接下来，定义由策略 <!----> 诱导的马尔可夫链的平稳分布，并引入相关变量：</p><ol><li><p><strong>平稳分布</strong> 设<!----> 表示由 <!---->诱导的马尔可夫链在所有状态上的平稳分布，<!----> 表示智能体 i在所有状态-动作对$ (s, a^i) \in S \times A^i$上的平稳分布。</p></li><li><p><strong>最小平稳分布概率</strong> 定义最小平稳分布概率<!---->为：</p></li></ol><p>$ \mu_{\text{min}, k} := \min_{i \in [N]} \min_{(s, a^i) \in S \times A^i} \mu^i_{\pi_k}(s, a^i)$</p><p>该变量表示从每个智能体的视角来看，所有状态-动作对的最小平稳分布概率。当 <!----> 较小时，需要更多样本以确保在第<!---->次探索阶段中所有状态-动作对被充分访问。</p><ol start="3"><li><strong>混合时间</strong> 对于第 k次探索阶段中智能体 i 的混合时间定义为：</li></ol><p>$ t^i_{\text{mix}, k}(\alpha) := \min \left{ t \Big| \max_{(s_0, a^i_0) \in S \times A^i} d_{\text{TV}}\left(P^t(\cdot | s_0, a^i_0), \mu^i_{\pi_k}\right) \leq \alpha \right}$</p><p>其中 <!---->，<!----> 表示在初始状态-动作对 <!----> 下<!---->时刻的分布，<!----> 表示总变差距离。混合时间描述了马尔可夫链从初始状态-动作对到平稳分布所需的时间。</p><ol start="4"><li><strong>最小分离量</strong> 定义所有智能体的最优 Q 函数之间的最小分离量 <!----> 为容差阈值的上界：</li></ol><!----><p>最后，定义了算法样本复杂度的主定理 (Theorem 1)，并在后续内容中导出了最小平稳分布概率和混合时间的上下界</p><hr><h3 id="theorem-1-定理1-非渐近收敛性及样本复杂度" tabindex="-1">Theorem 1（定理1）：非渐近收敛性及样本复杂度 <a class="header-anchor" href="#theorem-1-定理1-非渐近收敛性及样本复杂度" aria-label="Permalink to &quot;Theorem 1（定理1）：非渐近收敛性及样本复杂度&quot;">​</a></h3><p>定理 1 (Theorem 1)</p><p>考虑一个在严格最佳应对 (strict best replies) 下弱非循环的折扣随机博弈。假设每个智能体按照算法1来更新其策略，并满足假设1和假设2。则对于任意 <!---->，存在常数 <!----> 和 <!---->，使得对于所有 <!---->，有以下结果：</p><!----><p>其中，如果对于所有 <!----> 和 <!---->，以下条件成立：</p><ol><li><strong>探索阶段的长度条件</strong></li></ol><!----><p>这里，<!----> 是第 <!----> 次探索阶段的长度，<!---->是由联合策略<!----> 引导的马尔可夫链的最小平稳分布概率，<!----> 是混合时间，<!----> 是折现因子，<!----> 是算法的容差。</p><ol><li><strong>探索阶段数量条件</strong><!---->必须满足以下关系：</li></ol><!----><p>其中，<!---->是所有联合策略 <!----> 到均衡策略的最小概率，<!----> 表示最短严格最佳应对路径的长度。</p><ol><li><strong>步长条件</strong>对于所有时间步 <!---->，步长 <!----> 必须满足：</li></ol><!----><ol><li><strong>实验概率条件</strong>实验概率 <!----> 需设置为：</li></ol><!----><ol><li><strong>容差条件</strong>每个智能体的容差 <!----> 设为：</li></ol><p><!---->。</p><p>在这些条件下，定理1提供了算法1的有限样本收敛性结果，保证了算法在有限样本下收敛到某个均衡策略的概率至少为<!---->。</p><p>定理1的重要意义在于，它表明该分散式Q学习算法可以在有限样本条件下，以高概率收敛到一个近似均衡状态。这对于无法观测其他智能体策略和奖励的分散式环境中的学习任务具有重要价值，使算法在实际应用中更加可行和高效。</p><h3 id="proposition-2-命题2-样本复杂度的参数依赖性" tabindex="-1">Proposition 2（命题2）：样本复杂度的参数依赖性 <a class="header-anchor" href="#proposition-2-命题2-样本复杂度的参数依赖性" aria-label="Permalink to &quot;Proposition 2（命题2）：样本复杂度的参数依赖性&quot;">​</a></h3><p><strong>命题2</strong>进一步分析了定理1中的样本复杂度 (N(\epsilon, \delta))，并推导出它与一些关键参数之间的依赖关系。这些参数包括<strong>折现因子</strong> (\gamma)、<strong>最小稳态分布概率</strong> (\mu_{\text{min}})和<strong>混合时间</strong> (t_{\text{mix}})。</p><h4 id="命题2的内容" tabindex="-1">命题2的内容 <a class="header-anchor" href="#命题2的内容" aria-label="Permalink to &quot;命题2的内容&quot;">​</a></h4><p>命题2指出，算法的样本复杂度 <!----> 与以下三个参数密切相关：</p><ol><li><strong>折现因子</strong><!---->：控制未来奖励在Q值计算中的权重。当 <!----> 较大时，智能体更加重视未来的回报，这会使得Q值更新更加缓慢，样本复杂度随之增加。</li><li><strong>最小稳态分布概率</strong><!---->：假设1中的稳态分布最小概率，表示系统在长期稳定状态下访问每个状态的最低概率。当 <!---->较小时，某些状态可能很少被访问到，从而增加了Q值学习的样本复杂度。</li><li><strong>混合时间</strong><!---->：表示马尔可夫链从任意初始状态达到稳态分布所需的时间。混合时间越长，系统达到稳定分布所需的探索时间越长，从而增加了样本复杂度。</li></ol><p>命题 2 (Proposition 2)</p><p>对于所有 <!----> 和 <!---->，以下不等式成立：</p><ol><li><strong>最小平稳分布概率的上界</strong></li></ol><p><!---->。</p><p>这里，<!----> 表示智能体 <!----> 在探索阶段 <!----> 中的最小平稳分布概率，<!----> 是智能体<!----> 的实验概率，<!----> 是智能体 <!---->的动作空间大小，<!----> 是状态空间大小，<!----> 和 <!----> 是假设1中的常数。</p><ol><li><strong>最小平稳分布概率的下界</strong></li></ol><!----><p>该不等式给出了最小平稳分布概率的下界，表示在探索阶段 <!---->中，马尔可夫链的状态-动作对的平稳分布至少为上式中的值。</p><ol><li><strong>混合时间的上界</strong></li></ol><!----><p>其中，<!----> 表示在探索阶段 <!---->中，智能体 <!----> 达到总变差 <!----> 所需的混合时间。上界表示该混合时间随着 <!----> 的减小会增加，但其值不会过大，因为马尔可夫链是指数收敛的。</p><h4 id="命题2的解释与意义" tabindex="-1">命题2的解释与意义 <a class="header-anchor" href="#命题2的解释与意义" aria-label="Permalink to &quot;命题2的解释与意义&quot;">​</a></h4><ul><li><strong>参数依赖性</strong>：命题2指出了样本复杂度如何受折现因子、最小稳态分布概率和混合时间的影响。特别地： <ul><li><!----> <strong>越接近1</strong>（即智能体更重视未来的回报），样本复杂度会显著增加，因为Q值更新需要更多迭代来反映长期的累积回报。</li><li><!----> <strong>较小时</strong>，某些状态被访问的概率非常低，导致Q表中某些状态-动作对的估计需要更多样本来精确反映。</li><li><strong>较长的混合时间</strong><!----> 表明系统从任意初始状态到达稳态所需的时间较长，这意味着需要较长的探索阶段来确保系统接近稳态。</li></ul></li></ul><p>命题2的推导结果为算法在实际应用中的参数选择提供了指导，通过调整这些参数可以在样本复杂度和学习精度之间找到平衡点。</p><h3 id="corollary-1-推论1-在特殊情况下的收敛性改进" tabindex="-1">Corollary 1（推论1）：在特殊情况下的收敛性改进 <a class="header-anchor" href="#corollary-1-推论1-在特殊情况下的收敛性改进" aria-label="Permalink to &quot;Corollary 1（推论1）：在特殊情况下的收敛性改进&quot;">​</a></h3><p><strong>推论1</strong>在定理1和命题2的基础上，进一步讨论了一种特殊情况下的收敛性改进。该推论表明，如果在某些条件下调整参数，可以实现更快的收敛，减少样本复杂度。</p><h4 id="推论1的内容" tabindex="-1">推论1的内容 <a class="header-anchor" href="#推论1的内容" aria-label="Permalink to &quot;推论1的内容&quot;">​</a></h4><p>假设满足定理1中的所有条件，且假设最小稳态分布概率 <!----> 和混合时间 <!---->满足某些优化条件，则样本复杂度 <!---->可以降低一个量级。</p><p>形式上可以表示为：</p><!----><h4 id="推论1的解释与意义" tabindex="-1">推论1的解释与意义 <a class="header-anchor" href="#推论1的解释与意义" aria-label="Permalink to &quot;推论1的解释与意义&quot;">​</a></h4><ul><li><strong>样本复杂度的改进</strong>：推论1表明，在某些特殊条件下，样本复杂度可以较原始的复杂度降低一个量级。这意味着在某些优化参数下，算法可以更快速地达到指定的近似均衡。</li><li><strong>实际意义</strong>：推论1为算法的参数调优提供了进一步的方向。通过满足某些条件，可以有效减少所需的样本数，提高算法的学习效率。</li></ul><p>推论1的结果为实际应用提供了更优化的样本复杂度参考。在满足特定条件的情况下，用户可以选择适当的参数组合，以减少学习成本并提高收敛速度。</p><h3 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h3><ul><li><strong>定理1</strong>提供了在有限样本条件下，分散式Q学习算法收敛到(\epsilon)-近似均衡的非渐近收敛保证，并给出了所需的样本复杂度。</li><li><strong>命题2</strong>分析了样本复杂度与关键参数（折现因子、最小稳态分布概率、混合时间）之间的关系，为参数选择提供了理论指导。</li><li><strong>推论1</strong>进一步指出在特定条件下的样本复杂度改进，使算法在实际应用中具有更高的效率和适应性。</li></ul><p>这些理论结果为分散式Q学习算法在多智能体弱循环随机博弈中的收敛性和样本复杂度提供了全面的分析和指导，使算法在实践中的参数选择更具针对性和优化空间。</p><h2 id="补充" tabindex="-1">补充： <a class="header-anchor" href="#补充" aria-label="Permalink to &quot;补充：&quot;">​</a></h2><p><strong>弱循环随机博弈</strong>（Weakly Acyclic Stochastic Game）是一类特殊的多智能体随机博弈，它具有一些独特的结构特征，使得多智能体在这种博弈环境中更容易通过最优策略的调整来达到稳定的均衡状态。弱循环随机博弈的设计和分析通常用于确保多智能体系统能够收敛到某种均衡策略。</p><h4 id="弱循环随机博弈的定义和特性" tabindex="-1">弱循环随机博弈的定义和特性 <a class="header-anchor" href="#弱循环随机博弈的定义和特性" aria-label="Permalink to &quot;弱循环随机博弈的定义和特性&quot;">​</a></h4><p>在弱循环随机博弈中，博弈的主要特点是：</p><ol><li><strong>存在到均衡的路径</strong> 对于每个初始策略组合，都存在一条通过一系列策略更新可以达到均衡状态的路径。这种路径是有限且可达的，即使可能需要多步策略调整。简单来说，弱循环博弈允许存在策略调整的回路，但从任何策略组合出发，最终都可以通过最优回复（Best Reply）找到通向均衡的路径。</li><li><strong>最优回复路径</strong> 在弱循环博弈中，各智能体可以按照某种“最优回复”机制来调整其策略，使得在策略调整的过程中，不同智能体间的策略调整不会形成不可避免的永久性循环。也就是说，即使在局部调整策略时可能形成短暂的回路，但最终可以通过一条“严格的最优回复路径”达到某个均衡。</li><li><strong>弱循环性（Weak Acyclicity）</strong> 弱循环博弈不要求所有策略调整路径都能避免循环，但它允许有些策略路径形成回路，只要这些回路不会导致系统陷入无法到达均衡的振荡状态。也就是说，即使策略路径中存在循环，也有办法保证所有智能体的策略组合最终能够收敛到一个均衡点。</li></ol><h4 id="弱循环随机博弈的正式定义" tabindex="-1">弱循环随机博弈的正式定义 <a class="header-anchor" href="#弱循环随机博弈的正式定义" aria-label="Permalink to &quot;弱循环随机博弈的正式定义&quot;">​</a></h4><p>对于一个包含有限状态集 SSS 和动作集的多智能体随机博弈，若该博弈满足以下条件，则称之为弱循环随机博弈：</p><ul><li><strong>均衡策略的存在性</strong>：存在一个或多个均衡策略组合（如马尔可夫完美均衡）。</li><li><strong>严格最优回复路径</strong>：对于任何非均衡的策略组合，都存在至少一条最优回复路径，使得智能体可以逐步调整策略，并最终达到某个均衡点。</li><li><strong>路径有限性</strong>：每条最优回复路径的长度是有限的，即从任意非均衡的策略组合出发，经过有限次策略调整后可以达到均衡。</li></ul><h4 id="示例-策略调整路径与弱循环性" tabindex="-1">示例：策略调整路径与弱循环性 <a class="header-anchor" href="#示例-策略调整路径与弱循环性" aria-label="Permalink to &quot;示例：策略调整路径与弱循环性&quot;">​</a></h4><p>在一个弱循环博弈中，假设存在五个策略组合 <!---->，其中策略组合 <!----> 是一个均衡点。尽管可能存在策略路径形成短暂的循环（如 <!---->），但是在某些策略组合上进行适当调整后，智能体能够最终选择一条严格最优的路径到达均衡点 <!---->。</p><h4 id="弱循环博弈的意义" tabindex="-1">弱循环博弈的意义 <a class="header-anchor" href="#弱循环博弈的意义" aria-label="Permalink to &quot;弱循环博弈的意义&quot;">​</a></h4><p>弱循环随机博弈的设计旨在确保系统的策略组合能够收敛到某种均衡状态，即使智能体之间存在有限的策略调整循环。相比于一般的随机博弈，弱循环博弈的这种结构特性为收敛性提供了理论保障，避免了系统在动态调整过程中陷入无限振荡。这一性质对于设计多智能体学习算法（如分散式Q-learning）尤为重要，因为它允许各个智能体在动态环境中逐步找到稳定的均衡策略组合。</p><h4 id="应用场景" tabindex="-1">应用场景 <a class="header-anchor" href="#应用场景" aria-label="Permalink to &quot;应用场景&quot;">​</a></h4><p>弱循环随机博弈常用于需要多智能体协作且不存在全局控制的场景，例如：</p><ul><li><strong>交通信号控制</strong>：不同的信号灯通过调整信号策略实现交通流的优化，最终趋于一个稳定的交通流控制策略。</li><li><strong>分布式能源管理</strong>：在智能电网中，各能量资源在无需全局协调的情况下调整策略，实现区域或全网的能量平衡。</li><li><strong>多机器人系统</strong>：多个机器人在同一环境中执行任务，各自调整策略，以便在不发生冲突的前提下实现协作。</li></ul></div></div></main><footer class="VPDocFooter" data-v-5403d36d data-v-4ce2f229><!--[--><!--]--><div class="edit-info" data-v-4ce2f229><!----><div class="last-updated" data-v-4ce2f229><p class="VPLastUpdated" data-v-4ce2f229 data-v-b146320d>Last updated: <time datetime="2024-11-13T11:23:41.000Z" data-v-b146320d></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-4ce2f229><span class="visually-hidden" id="doc-footer-aria-label" data-v-4ce2f229>Pager</span><div class="pager" data-v-4ce2f229><a class="VPLink link pager-link prev" href="/feishu__2024_9_16_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95_%E4%BC%98%E5%8C%96%E6%8E%A7%E5%88%B6.html" data-v-4ce2f229><!--[--><span class="desc" data-v-4ce2f229>Previous page</span><span class="title" data-v-4ce2f229>优化控制</span><!--]--></a></div><div class="pager" data-v-4ce2f229><a class="VPLink link pager-link next" href="/feishu__2024_10_1_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86.html" data-v-4ce2f229><!--[--><span class="desc" data-v-4ce2f229>Next page</span><span class="title" data-v-4ce2f229>学习笔记整理</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"en_api-examples.md\":\"-yEtf-Uw\",\"en_feishu__2024_10_14_旅途记录_中国_浙江.md\":\"DrH5mqb2\",\"en_feishu__2024_10_14_旅途记录_中国_浙江_绍兴.md\":\"Bo5PsutZ\",\"en_feishu__2024_10_15_技术博客_vscode编译latex教程.md\":\"CwzKIlho\",\"en_feishu__2024_10_1_学习笔记_学习笔记整理.md\":\"DMUCaM7m\",\"en_feishu__2024_10_1_学习笔记_学习笔记整理_偏微分方程求解总结.md\":\"DV-cJNvU\",\"en_feishu__2024_10_1_技术博客_偏微分方程求解总结.md\":\"C2o959KP\",\"en_feishu__2024_10_1_旅途记录_中国_上海.md\":\"DdQRXpWs\",\"en_feishu__2024_10_1_旅途记录_中国_上海_临港 滴水湖 东海.md\":\"-nAkFWLQ\",\"en_feishu__2024_10_1_旅途记录_中国_上海_外滩 陆家嘴.md\":\"BCO2mO7e\",\"en_feishu__2024_10_1_旅途记录_中国_云南.md\":\"D_ySRQcx\",\"en_feishu__2024_10_1_旅途记录_中国_北京.md\":\"C9oNQfs-\",\"en_feishu__2024_10_1_旅途记录_中国_四川.md\":\"GXrw2-E-\",\"en_feishu__2024_10_1_旅途记录_中国_广东.md\":\"Co8rlLv_\",\"en_feishu__2024_10_5_学习笔记_学习笔记整理_名词词典.md\":\"4ncv0_tB\",\"en_feishu__2024_10_5_学习笔记_论文阅读记录_量子计算_各向异性不变性和量子相关的分布论文阅读.md\":\"Zp0en-Fb\",\"en_feishu__2024_10_7_学习笔记_学习笔记整理_量子理论.md\":\"DMN7xsPM\",\"en_feishu__2024_10_7_学习笔记_学习笔记整理_量子理论_高等量子力学学习笔记.md\":\"C3pElmpX\",\"en_feishu__2024_10_8_旅途记录_中国_广东_深圳.md\":\"4zwSR2tD\",\"en_feishu__2024_8_26__日常博客.md\":\"7sqV0yTb\",\"en_feishu__2024_8_26__首页.md\":\"1GoGY15a\",\"en_feishu__2024_8_26_日常博客_个人博客搭建纪念.md\":\"BWC4a67d\",\"en_feishu__2024_8_26_首页_测试子页面.md\":\"BlAHpaup\",\"en_feishu__2024_8_27__学习笔记.md\":\"DK3xHerw\",\"en_feishu__2024_8_27_学习笔记_论文导读.md\":\"Bpc5Uotv\",\"en_feishu__2024_8_27_学习笔记_论文阅读记录.md\":\"5opa9ewB\",\"en_feishu__2024_8_27_学习笔记_论文阅读记录_量子计算.md\":\"gS6wEfSv\",\"en_feishu__2024_8_27_学习笔记_论文阅读记录_量子计算_optimal simulation of deutsch gates and the fredkin gate.md\":\"CrUFwwmB\",\"en_feishu__2024_8_28_学习笔记_论文阅读记录_量子计算_fast multiqubit gates through simultaneous two-qubit gates.md\":\"Do_8awTJ\",\"en_feishu__2024_9_16_学习笔记_ai基本范式学习.md\":\"CjKAgnM4\",\"en_feishu__2024_9_16_学习笔记_ai基本范式学习_强化学习.md\":\"DYKp8Y9U\",\"en_feishu__2024_9_16_学习笔记_ai学习.md\":\"IosmGRXz\",\"en_feishu__2024_9_16_学习笔记_ai学习_强化学习.md\":\"CKsSQUCa\",\"en_feishu__2024_9_16_学习笔记_学习笔记整理_ai学习.md\":\"B1PZZZBu\",\"en_feishu__2024_9_16_学习笔记_学习笔记整理_ai学习_强化学习.md\":\"BaEDhFs-\",\"en_feishu__2024_9_16_学习笔记_论文阅读记录_优化控制.md\":\"HRYX0Pnq\",\"en_feishu__2024_9_16_学习笔记_论文阅读记录_优化控制_.md\":\"BU3hICn2\",\"en_feishu__2024_9_16_学习笔记_论文阅读记录_优化控制_随机博弈分散式表q-learning的样本复杂度.md\":\"vLst6843\",\"en_feishu__2024_9_31__技术博客.md\":\"C_9lkQhp\",\"en_feishu__2024_9_31__旅途记录.md\":\"BtjY9IP8\",\"en_feishu__2024_9_31_学习笔记_论文导读_prl  volume 133 部分文章导读.md\":\"Mj8ObdUj\",\"en_feishu__2024_9_31_技术博客_vitepress网站搭建与更新记录.md\":\"uqIjjX3h\",\"en_feishu__2024_9_31_旅途记录_中国.md\":\"CaBCdYPR\",\"en_feishu__2024_9_6_学习笔记_论文阅读记录_量子计算_变分量子kan.md\":\"B1XKMaei\",\"en_feishu__2024_9_8_学习笔记_论文阅读记录_量子计算_无监督学习检测量子纠缠.md\":\"D5qIl6ig\",\"en_index.md\":\"UpwRdGZn\",\"en_markdown-examples.md\":\"DOmqe7oQ\",\"feishu__2024_10_14_旅途记录_中国_浙江.md\":\"Bq7dfoZ1\",\"feishu__2024_10_14_旅途记录_中国_浙江_绍兴.md\":\"DXVtIdPp\",\"feishu__2024_10_15_技术博客_vscode编译latex教程.md\":\"bonTv4Dv\",\"feishu__2024_10_1_学习笔记_学习笔记整理.md\":\"B4ywx9BP\",\"feishu__2024_10_1_技术博客_偏微分方程求解总结.md\":\"D7PJI0ux\",\"feishu__2024_10_1_旅途记录_中国_上海.md\":\"BaJFqzC3\",\"feishu__2024_10_1_旅途记录_中国_上海_临港 滴水湖 东海.md\":\"DjIgXs6g\",\"feishu__2024_10_1_旅途记录_中国_上海_外滩 陆家嘴.md\":\"BcU1aYBn\",\"feishu__2024_10_1_旅途记录_中国_云南.md\":\"C-bsvj6b\",\"feishu__2024_10_1_旅途记录_中国_北京.md\":\"2JFPiyL3\",\"feishu__2024_10_1_旅途记录_中国_四川.md\":\"BUR6_k7G\",\"feishu__2024_10_1_旅途记录_中国_广东.md\":\"BaC1G1HZ\",\"feishu__2024_10_5_学习笔记_学习笔记整理_名词词典.md\":\"C3uFeTiM\",\"feishu__2024_10_5_学习笔记_论文阅读记录_量子计算_各向异性不变性和量子相关的分布论文阅读.md\":\"D71Uf-SQ\",\"feishu__2024_10_7_学习笔记_学习笔记整理_量子理论.md\":\"BEYnnM9R\",\"feishu__2024_10_7_学习笔记_学习笔记整理_量子理论_高等量子力学学习笔记.md\":\"Vf4KOKvG\",\"feishu__2024_10_8_旅途记录_中国_广东_深圳.md\":\"BRq-vmsI\",\"feishu__2024_8_26__日常博客.md\":\"D2M1Ao1G\",\"feishu__2024_8_26_日常博客_个人博客搭建纪念.md\":\"CdxVl-6-\",\"feishu__2024_8_27__学习笔记.md\":\"Bfs8_Hu8\",\"feishu__2024_8_27_学习笔记_论文导读.md\":\"CJPfdQ3p\",\"feishu__2024_8_27_学习笔记_论文阅读记录.md\":\"CFNKbBQp\",\"feishu__2024_8_27_学习笔记_论文阅读记录_量子计算.md\":\"CvDoNBp3\",\"feishu__2024_8_27_学习笔记_论文阅读记录_量子计算_optimal simulation of deutsch gates and the fredkin gate.md\":\"D1Zpvnsq\",\"feishu__2024_8_28_学习笔记_论文阅读记录_量子计算_fast multiqubit gates through simultaneous two-qubit gates.md\":\"BBYuU9qG\",\"feishu__2024_9_16_学习笔记_学习笔记整理_ai学习.md\":\"DhK9jLMx\",\"feishu__2024_9_16_学习笔记_学习笔记整理_ai学习_强化学习.md\":\"Crv2aVFU\",\"feishu__2024_9_16_学习笔记_论文阅读记录_优化控制.md\":\"BJV9gcZ4\",\"feishu__2024_9_16_学习笔记_论文阅读记录_优化控制_.md\":\"BH95Rui8\",\"feishu__2024_9_16_学习笔记_论文阅读记录_优化控制_随机博弈分散式表q-learning的样本复杂度.md\":\"BwL8PZpo\",\"feishu__2024_9_31__技术博客.md\":\"c6g9GvSH\",\"feishu__2024_9_31__旅途记录.md\":\"DTd0I1Sl\",\"feishu__2024_9_31_学习笔记_论文导读_prl  volume 133 部分文章导读.md\":\"B2FYblzx\",\"feishu__2024_9_31_技术博客_vitepress网站搭建与更新记录.md\":\"D62o1Gqo\",\"feishu__2024_9_31_旅途记录_中国.md\":\"Dg0b1zrM\",\"feishu__2024_9_6_学习笔记_论文阅读记录_量子计算_变分量子kan.md\":\"_gHzm_Dk\",\"feishu__2024_9_8_学习笔记_论文阅读记录_量子计算_无监督学习检测量子纠缠.md\":\"Dqncmyo8\",\"index.md\":\"DNOhvBXV\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"个人博客\",\"description\":\"一个记录生活与学习笔记的平台\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"search\":{\"provider\":\"local\",\"options\":{\"locales\":{\"zh\":{\"translations\":{\"button\":{\"buttonText\":\"搜索文档\",\"buttonAriaLabel\":\"搜索文档\"},\"modal\":{\"noResultsText\":\"无法找到相关结果\",\"resetButtonTitle\":\"清除查询条件\",\"footer\":{\"selectText\":\"选择\",\"navigateText\":\"切换\"}}}}}}},\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"日常博客\",\"link\":\"/feishu__2024_8_26__日常博客\"},{\"text\":\"学习笔记\",\"link\":\"/feishu__2024_8_27__学习笔记\"},{\"text\":\"技术博客\",\"link\":\"/feishu__2024_9_31__技术博客\"},{\"text\":\"旅途记录\",\"link\":\"/feishu__2024_9_31__旅途记录\"}],\"sidebar\":[{\"text\":\"日常博客\",\"link\":\"/feishu__2024_8_26__日常博客\",\"items\":[{\"text\":\"个人博客搭建纪念\",\"link\":\"/feishu__2024_8_26_日常博客_个人博客搭建纪念\"}],\"collapsed\":false},{\"text\":\"技术博客\",\"link\":\"/feishu__2024_9_31__技术博客\",\"items\":[{\"text\":\"Vitepress网站搭建与更新记录\",\"link\":\"/feishu__2024_9_31_技术博客_vitepress网站搭建与更新记录\"},{\"text\":\"偏微分方程求解总结\",\"link\":\"/feishu__2024_10_1_技术博客_偏微分方程求解总结\"},{\"text\":\"VScode编译latex教程\",\"link\":\"/feishu__2024_10_15_技术博客_vscode编译latex教程\"}],\"collapsed\":false},{\"text\":\"旅途记录\",\"link\":\"/feishu__2024_9_31__旅途记录\",\"items\":[{\"text\":\"中国\",\"link\":\"/feishu__2024_9_31_旅途记录_中国\",\"items\":[{\"text\":\"上海\",\"link\":\"/feishu__2024_10_1_旅途记录_中国_上海\",\"items\":[{\"text\":\"外滩 陆家嘴\",\"link\":\"/feishu__2024_10_1_旅途记录_中国_上海_外滩 陆家嘴\"},{\"text\":\"临港 滴水湖 东海\",\"link\":\"/feishu__2024_10_1_旅途记录_中国_上海_临港 滴水湖 东海\"}],\"collapsed\":false},{\"text\":\"云南\",\"link\":\"/feishu__2024_10_1_旅途记录_中国_云南\"},{\"text\":\"北京\",\"link\":\"/feishu__2024_10_1_旅途记录_中国_北京\"},{\"text\":\"广东\",\"link\":\"/feishu__2024_10_1_旅途记录_中国_广东\",\"items\":[{\"text\":\"深圳\",\"link\":\"/feishu__2024_10_8_旅途记录_中国_广东_深圳\"}],\"collapsed\":false},{\"text\":\"四川\",\"link\":\"/feishu__2024_10_1_旅途记录_中国_四川\"},{\"text\":\"浙江\",\"link\":\"/feishu__2024_10_14_旅途记录_中国_浙江\",\"items\":[{\"text\":\"绍兴\",\"link\":\"/feishu__2024_10_14_旅途记录_中国_浙江_绍兴\"}],\"collapsed\":false}],\"collapsed\":false}],\"collapsed\":false},{\"text\":\"学习笔记\",\"link\":\"/feishu__2024_8_27__学习笔记\",\"items\":[{\"text\":\"论文导读\",\"link\":\"/feishu__2024_8_27_学习笔记_论文导读\",\"items\":[{\"text\":\"PRL Volume 133 部分文章导读\",\"link\":\"/feishu__2024_9_31_学习笔记_论文导读_prl  volume 133 部分文章导读\"}],\"collapsed\":false},{\"text\":\"论文阅读记录\",\"link\":\"/feishu__2024_8_27_学习笔记_论文阅读记录\",\"items\":[{\"text\":\"量子计算\",\"link\":\"/feishu__2024_8_27_学习笔记_论文阅读记录_量子计算\",\"items\":[{\"text\":\"Optimal simulation of Deutsch gates and the Fredkin gate\",\"link\":\"/feishu__2024_8_27_学习笔记_论文阅读记录_量子计算_optimal simulation of deutsch gates and the fredkin gate\"},{\"text\":\"Fast Multiqubit Gates through Simultaneous Two-Qubit Gates\",\"link\":\"/feishu__2024_8_28_学习笔记_论文阅读记录_量子计算_fast multiqubit gates through simultaneous two-qubit gates\"},{\"text\":\"变分量子KAN\",\"link\":\"/feishu__2024_9_6_学习笔记_论文阅读记录_量子计算_变分量子kan\"},{\"text\":\"无监督学习检测量子纠缠\",\"link\":\"/feishu__2024_9_8_学习笔记_论文阅读记录_量子计算_无监督学习检测量子纠缠\"},{\"text\":\"各向异性不变性和量子相关的分布\",\"link\":\"/feishu__2024_10_5_学习笔记_论文阅读记录_量子计算_各向异性不变性和量子相关的分布论文阅读\"}],\"collapsed\":false},{\"text\":\"优化控制\",\"link\":\"/feishu__2024_9_16_学习笔记_论文阅读记录_优化控制\",\"items\":[{\"text\":\"随机博弈分散式表q-learning的样本复杂度\",\"link\":\"/feishu__2024_9_16_学习笔记_论文阅读记录_优化控制_随机博弈分散式表q-learning的样本复杂度\"}],\"collapsed\":false}],\"collapsed\":false},{\"text\":\"学习笔记整理\",\"link\":\"/feishu__2024_10_1_学习笔记_学习笔记整理\",\"items\":[{\"text\":\"名词词典及解释\",\"link\":\"/feishu__2024_10_5_学习笔记_学习笔记整理_名词词典\"},{\"text\":\"量子理论\",\"link\":\"/feishu__2024_10_7_学习笔记_学习笔记整理_量子理论\",\"items\":[{\"text\":\"高等量子力学学习笔记\",\"link\":\"/feishu__2024_10_7_学习笔记_学习笔记整理_量子理论_高等量子力学学习笔记\"}],\"collapsed\":false},{\"text\":\"AI学习\",\"link\":\"/feishu__2024_9_16_学习笔记_学习笔记整理_ai学习\",\"items\":[{\"text\":\"强化学习\",\"link\":\"/feishu__2024_9_16_学习笔记_学习笔记整理_ai学习_强化学习\"}],\"collapsed\":false}],\"collapsed\":false}],\"collapsed\":false}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/xuehaimoyu\"}]},\"locales\":{\"root\":{\"label\":\"中文\",\"lang\":\"中文\"},\"en\":{\"label\":\"English\",\"lang\":\"en\"}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>